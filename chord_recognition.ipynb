{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import keras\n",
    "import os, glob\n",
    "import librosa, librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "from keras.layers import Activation, Dense, Dropout, Conv2D, \\\n",
    "                         Flatten, MaxPooling2D\n",
    "from keras.models import Sequential, model_from_json\n",
    "from keras import backend as K\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR_GUITAR = \"./data/audio/Guitar_Only/\"\n",
    "CLASSES = ['a', 'am', 'bm', 'c', 'd', 'dm', 'e', 'em', 'f', 'g']\n",
    "CLASSES_MAP = {'a':0, 'am':1, 'bm':2, 'c':3, 'd':4, 'dm':5, 'e':6, 'em':7, 'f':8, 'g':9}\n",
    "METADATA_DIR_RAW = \"./data/metadata/raw/\"\n",
    "METADATA_DIR_PROCESSED = \"./data/metadata/processed/\"\n",
    "DATA_DIR_AUGMENTED = \"./data/augmented/\"\n",
    "METADATA_DIR_AUGMENTED_RAW = \"./data/augmented/raw\"\n",
    "METADATA_DIR_AUGMENTED_PROCESSED = \"./data/augmented/processed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(glob.glob(DATA_DIR_GUITAR + \"**/*.wav\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_info(f):\n",
    "    def inner(df, *args, **kwargs):\n",
    "        result = f(df, *args, **kwargs)\n",
    "        print(f\"After applying {f.__name__}, shape of df = {result.shape }\")\n",
    "        print(f\"Columns of df are {df.columns}\\n\")\n",
    "        return result\n",
    "    return inner\n",
    "\n",
    "# Construct Dataframe with all required values\n",
    "@df_info\n",
    "def construct_dataframe(df):\n",
    "    df['file_path'] = file_path\n",
    "    df['file_path'] = df['file_path'].map(lambda x: x[x.rindex('Only\\\\')+len('Only\\\\'):])\n",
    "    df['file_name'] = df['file_path'].map(lambda x: x[x.rindex('\\\\')+1:])\n",
    "    df['class_name'] = df['file_path'].map(lambda x: x[:x.index('\\\\')])\n",
    "    df['class_ID'] = df['class_name'].map(lambda x: CLASSES_MAP[x])\n",
    "    return df.copy()\n",
    "\n",
    "# Extract spectrogram from audio\n",
    "@df_info\n",
    "def get_spectrogram(df):\n",
    "    df['audio_series'] = df['file_path'].map(lambda x: librosa.load(DATA_DIR_GUITAR + x, duration=2))\n",
    "    df['y'] = df['audio_series'].map(lambda x: x[0])\n",
    "    df['sr'] = df['audio_series'].map(lambda x: x[1])\n",
    "    df['spectrogram'] = df.apply(lambda row: librosa.feature.melspectrogram(y=row['y'], sr=row['sr']), axis=1)\n",
    "    df.drop(columns='audio_series', inplace=True)\n",
    "    return df\n",
    "\n",
    "@df_info\n",
    "def get_count(df):\n",
    "    return df['class_name'].value_counts()\n",
    "\n",
    "@df_info\n",
    "def add_shape(df):\n",
    "    df['shape'] = df['spectrogram'].map(lambda x: x.shape)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After applying construct_dataframe, shape of df = (2000, 4)\n",
      "Columns of df are Index(['file_path', 'file_name', 'class_name', 'class_ID'], dtype='object')\n",
      "\n",
      "After applying get_spectrogram, shape of df = (2000, 7)\n",
      "Columns of df are Index(['file_path', 'file_name', 'class_name', 'class_ID', 'y', 'sr',\n",
      "       'spectrogram'],\n",
      "      dtype='object')\n",
      "\n",
      "After applying add_shape, shape of df = (2000, 8)\n",
      "Columns of df are Index(['file_path', 'file_name', 'class_name', 'class_ID', 'y', 'sr',\n",
      "       'spectrogram', 'shape'],\n",
      "      dtype='object')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "file_path = glob.glob(\"./data/audio/Guitar_Only/\" + \"**/*.wav\")\n",
    "data_df_raw = (pd.DataFrame().pipe(construct_dataframe)\n",
    "                            .pipe(get_spectrogram)\n",
    "                             .pipe(add_shape)\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After applying get_count, shape of df = (10,)\n",
      "Columns of df are Index(['file_path', 'file_name', 'class_name', 'class_ID', 'y', 'sr',\n",
      "       'spectrogram', 'shape'],\n",
      "      dtype='object')\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "a     200\n",
       "am    200\n",
       "bm    200\n",
       "c     200\n",
       "d     200\n",
       "dm    200\n",
       "e     200\n",
       "em    200\n",
       "f     200\n",
       "g     200\n",
       "Name: class_name, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_count(data_df_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save raw data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_df_raw.to_csv(os.path.join(METADATA_DIR_RAW, 'data.csv'), index=False)\n",
    "data_df_raw.to_pickle(os.path.join(METADATA_DIR_RAW, 'data.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df_raw = pd.read_pickle(os.path.join(METADATA_DIR_RAW, 'data.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_df_raw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process and save processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maintain same shape\n",
    "@df_info\n",
    "def clean_shape(df):\n",
    "    max_shape = df['spectrogram'].map(lambda x: x.shape).value_counts().index[0]\n",
    "    print(f\"The most frequent shape is {max_shape}\")\n",
    "    df['shape'] = df['spectrogram'].map(lambda x: x.shape)\n",
    "    df = df[df['shape']==max_shape]\n",
    "    df.drop(columns='shape', inplace=True)\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    return df\n",
    "\n",
    "@df_info\n",
    "def process(df):\n",
    "    df = (df.pipe(clean_shape)\n",
    "                .pipe(over_sample)\n",
    "    )\n",
    "    df = df[['spectrogram','class_ID', 'class_name']]\n",
    "    return df\n",
    "\n",
    "#Over sampling data\n",
    "@df_info\n",
    "def over_sample(df):\n",
    "    oversample = RandomOverSampler(sampling_strategy='auto')\n",
    "    X, y = df['spectrogram'].values, df['class_ID'].values\n",
    "    X = X.reshape(-1, 1)\n",
    "    X, y = oversample.fit_resample(X, y)\n",
    "    df = pd.DataFrame()\n",
    "    df['spectrogram'] = pd.Series([np.array(x[0]) for x in X])\n",
    "    df['class_ID'] = pd.Series(y)\n",
    "    df['class_name'] = df['class_ID'].map(lambda x: get_class(x))\n",
    "    return df\n",
    "\n",
    "def get_class(class_ID):\n",
    "    return list(CLASSES_MAP.keys())[list(CLASSES_MAP.values()).index(class_ID)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most frequent shape is (128, 87)\n",
      "After applying clean_shape, shape of df = (633, 7)\n",
      "Columns of df are Index(['file_path', 'file_name', 'class_name', 'class_ID', 'y', 'sr',\n",
      "       'spectrogram', 'shape'],\n",
      "      dtype='object')\n",
      "\n",
      "After applying over_sample, shape of df = (1150, 3)\n",
      "Columns of df are Index(['file_path', 'file_name', 'class_name', 'class_ID', 'y', 'sr',\n",
      "       'spectrogram'],\n",
      "      dtype='object')\n",
      "\n",
      "After applying process, shape of df = (1150, 3)\n",
      "Columns of df are Index(['file_path', 'file_name', 'class_name', 'class_ID', 'y', 'sr',\n",
      "       'spectrogram', 'shape'],\n",
      "      dtype='object')\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shiva Kumar\\AppData\\Local\\Temp\\ipykernel_26788\\1589077470.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.drop(columns='shape', inplace=True)\n"
     ]
    }
   ],
   "source": [
    "data_df_processed = process(data_df_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After applying get_count, shape of df = (10,)\n",
      "Columns of df are Index(['spectrogram', 'class_ID', 'class_name'], dtype='object')\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "a     115\n",
       "am    115\n",
       "bm    115\n",
       "c     115\n",
       "d     115\n",
       "dm    115\n",
       "e     115\n",
       "em    115\n",
       "f     115\n",
       "g     115\n",
       "Name: class_name, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_count(data_df_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_df_processed.to_csv(os.path.join(METADATA_DIR_PROCESSED, 'data.csv'), index=False)\n",
    "data_df_processed.to_pickle(os.path.join(METADATA_DIR_PROCESSED, 'data.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_df_processed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examples of Siren spectrograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y, sr = librosa.load(DATA_DIR_GUITAR+data_df_raw['file_path'].iloc[0],duration=2)\n",
    "ps = librosa.feature.melspectrogram(y=y, sr=sr)\n",
    "ps.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "librosa.display.specshow(ps, y_axis='mel', x_axis='time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y, sr = librosa.load(DATA_DIR_GUITAR+data_df_raw['file_path'].iloc[201],duration=2)\n",
    "ps = librosa.feature.melspectrogram(y=y, sr=sr,)\n",
    "ps.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "librosa.display.specshow(ps, y_axis='mel', x_axis='time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y, sr = librosa.load(DATA_DIR_GUITAR+data_df_raw['file_path'].iloc[401],duration=2)\n",
    "ps = librosa.feature.melspectrogram(y=y, sr=sr,)\n",
    "ps.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "librosa.display.specshow(ps, y_axis='mel', x_axis='time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y, sr = librosa.load(DATA_DIR_GUITAR+data_df_raw['file_path'].iloc[801],duration=2)\n",
    "ps = librosa.feature.melspectrogram(y=y, sr=sr,)\n",
    "ps.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "librosa.display.specshow(ps, y_axis='mel', x_axis='time')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_pickle(os.path.join(METADATA_DIR_PROCESSED, 'data.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples:  1150\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of samples: \", len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['spectrogram'].iloc[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples is 920\n",
      "Number of testing samples is 230\n",
      "                                           spectrogram  class_ID class_name\n",
      "174  [[0.005131787, 0.007499365, 0.0060594357, 0.00...         3          c\n",
      "752  [[0.00054565433, 0.00068049034, 0.00044531203,...         2         bm\n",
      "467  [[0.0002861476, 0.00029724906, 0.00054549635, ...         6          e\n",
      "240  [[0.00024178192, 0.00020344825, 0.0005125338, ...         3          c\n",
      "667  [[7.849557e-05, 7.7419565e-05, 4.931826e-05, 0...         0          a\n",
      "218  [[4.0637336e-05, 2.8319037e-05, 1.5888332e-05,...         3          c\n",
      "867  [[0.00083518715, 0.001044225, 0.0008323917, 0....         4          d\n",
      "420  [[0.022283832, 0.009524431, 0.007829224, 0.008...         6          e\n",
      "351  [[0.0007388318, 0.0010725782, 0.0007419601, 0....         5         dm\n",
      "328  [[9.781871e-05, 0.0001397526, 0.00011793934, 0...         4          d\n",
      "                                          spectrogram  class_ID class_name\n",
      "1   [[0.007935312, 0.009195907, 0.0041631414, 0.00...         0          a\n",
      "13  [[0.0001222133, 0.00011055944, 0.00012506438, ...         0          a\n",
      "14  [[5.9300637e-05, 0.00017157476, 0.00025935465,...         0          a\n",
      "20  [[2.7541288e-05, 5.1521598e-05, 9.777481e-05, ...         0          a\n",
      "21  [[8.226129e-05, 6.553833e-05, 0.00025210707, 0...         0          a\n",
      "27  [[0.0001132001, 0.0003762157, 0.0002105905, 5....         0          a\n",
      "34  [[0.009080363, 0.008830369, 0.01579431, 0.0118...         1         am\n",
      "40  [[0.00636489, 0.008072853, 0.0049634837, 0.007...         1         am\n",
      "52  [[8.400516e-06, 1.5401049e-05, 0.0019543066, 0...         1         am\n",
      "64  [[0.006992169, 0.007906006, 0.004784775, 0.006...         1         am\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "sample = np.random.choice(dataset.index, size=int(len(dataset)*0.8), replace=False)\n",
    "train_data, test_data = dataset.iloc[sample], dataset.drop(sample)\n",
    "\n",
    "print(\"Number of training samples is\", len(train_data))\n",
    "print(\"Number of testing samples is\", len(test_data))\n",
    "print(train_data[:10])\n",
    "print(test_data[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['spectrogram'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spectrogram    [[0.005131787, 0.007499365, 0.0060594357, 0.00...\n",
      "class_ID                                                       3\n",
      "class_name                                                     c\n",
      "Name: 174, dtype: object\n",
      "(128, 87)\n",
      "0.007499365\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "print(train_data.iloc[0])\n",
    "print(train_data.iloc[0][0].shape)   #shape of input image\n",
    "print(train_data.iloc[0][0][0][1])\n",
    "print(train_data.iloc[0][1])    #output class id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the data into features (X) and targets (y)\n",
    "Now, as a final step before the training, we'll split the data into features (X) and targets (y)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "174    [[0.005131787, 0.007499365, 0.0060594357, 0.00...\n",
      "752    [[0.00054565433, 0.00068049034, 0.00044531203,...\n",
      "467    [[0.0002861476, 0.00029724906, 0.00054549635, ...\n",
      "240    [[0.00024178192, 0.00020344825, 0.0005125338, ...\n",
      "667    [[7.849557e-05, 7.7419565e-05, 4.931826e-05, 0...\n",
      "218    [[4.0637336e-05, 2.8319037e-05, 1.5888332e-05,...\n",
      "867    [[0.00083518715, 0.001044225, 0.0008323917, 0....\n",
      "420    [[0.022283832, 0.009524431, 0.007829224, 0.008...\n",
      "351    [[0.0007388318, 0.0010725782, 0.0007419601, 0....\n",
      "328    [[9.781871e-05, 0.0001397526, 0.00011793934, 0...\n",
      "Name: spectrogram, dtype: object\n",
      "174    3\n",
      "752    2\n",
      "467    6\n",
      "240    3\n",
      "667    0\n",
      "218    3\n",
      "867    4\n",
      "420    6\n",
      "351    5\n",
      "328    4\n",
      "Name: class_ID, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "X_train = train_data['spectrogram']\n",
    "y_train = train_data['class_ID']\n",
    "X_test = test_data['spectrogram']\n",
    "y_test = test_data['class_ID']\n",
    "\n",
    "print(X_train[:10])\n",
    "print(y_train[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshape for CNN input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array([x.reshape( (128, 87, 1) ) for x in X_train])\n",
    "X_test = np.array([x.reshape( (128, 87, 1) ) for x in X_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 87, 1)\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(X_train[0].shape)\n",
    "print(y_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-Hot encoding for classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array(keras.utils.to_categorical(y_train, 10))\n",
    "y_test_values=y_test\n",
    "y_test = np.array(keras.utils.to_categorical(y_test, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(y_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "input_shape=(128, 87, 1)\n",
    "\n",
    "model.add(Conv2D(24, (5, 5), strides=(1, 1), input_shape=input_shape))\n",
    "model.add(MaxPooling2D((4, 2), strides=(4, 2)))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Conv2D(48, (5, 5), padding=\"valid\"))\n",
    "model.add(MaxPooling2D((4, 2), strides=(4, 2)))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Conv2D(48, (5, 5), padding=\"valid\"))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(rate=0.4))\n",
    "\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(rate=0.4))\n",
    "\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 124, 83, 24)       624       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 31, 41, 24)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " activation (Activation)     (None, 31, 41, 24)        0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 27, 37, 48)        28848     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 6, 18, 48)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 6, 18, 48)         0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 2, 14, 48)         57648     \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 2, 14, 48)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 1344)              0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 1344)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                86080     \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 64)                0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                650       \n",
      "                                                                 \n",
      " activation_4 (Activation)   (None, 10)                0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 173,850\n",
      "Trainable params: 173,850\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision(y_true, y_pred):\n",
    "    '''Calculates the precision, a metric for multi-label classification of\n",
    "    how many selected items are relevant.\n",
    "    '''\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "\n",
    "def recall(y_true, y_pred):\n",
    "    '''Calculates the recall, a metric for multi-label classification of\n",
    "    how many relevant items are selected.\n",
    "    '''\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "\n",
    "def fbeta_score(y_true, y_pred, beta=1):\n",
    "    '''Calculates the F score, the weighted harmonic mean of precision and recall.\n",
    "    This is useful for multi-label classification, where input samples can be\n",
    "    classified as sets of labels. By only using accuracy (precision) a model\n",
    "    would achieve a perfect score by simply assigning every class to every\n",
    "    input. In order to avoid this, a metric should penalize incorrect class\n",
    "    assignments as well (recall). The F-beta score (ranged from 0.0 to 1.0)\n",
    "    computes this, as a weighted mean of the proportion of correct class\n",
    "    assignments vs. the proportion of incorrect class assignments.\n",
    "    With beta = 1, this is equivalent to a F-measure. With beta < 1, assigning\n",
    "    correct classes becomes more important, and with beta > 1 the metric is\n",
    "    instead weighted towards penalizing incorrect class assignments.\n",
    "    '''\n",
    "    if beta < 0:\n",
    "        raise ValueError('The lowest choosable beta is zero (only precision).')\n",
    "        \n",
    "    # If there are no true positives, fix the F score at 0 like sklearn.\n",
    "    if K.sum(K.round(K.clip(y_true, 0, 1))) == 0:\n",
    "        return 0.0\n",
    "\n",
    "    p = precision(y_true, y_pred)\n",
    "    r = recall(y_true, y_pred)\n",
    "    bb = beta ** 2\n",
    "    fbeta_score = (1 + bb) * (p * r) / (bb * p + r + K.epsilon())\n",
    "    return fbeta_score\n",
    "\n",
    "\n",
    "def fmeasure(y_true, y_pred):\n",
    "    '''Calculates the f-measure, the harmonic mean of precision and recall.\n",
    "    '''\n",
    "    return fbeta_score(y_true, y_pred, beta=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "\toptimizer=Adam(),\n",
    "\tloss=\"categorical_crossentropy\",\n",
    "\tmetrics=['accuracy', precision, recall,fmeasure])\n",
    "\n",
    "history = model.fit(\n",
    "\tx=X_train, \n",
    "\ty=y_train,\n",
    "    epochs=200,\n",
    "    batch_size=20,\n",
    "    validation_data= (X_test, y_test))\n",
    "\n",
    "score = model.evaluate(\n",
    "\tx=X_test,\n",
    "\ty=y_test)\n",
    "\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "print('Test precision:', score[2])\n",
    "print('Test recall:', score[3])\n",
    "print('Test f1-score:', score[4])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(230,)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(\u001b[43mhistory\u001b[49m\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m      2\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mModel Accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions = model.predict_classes(X_test)\n",
    "predict_x=model.predict(X_test) \n",
    "predictions=np.argmax(predict_x,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[55,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 1, 64,  0,  0,  0,  0,  1,  0,  0,  0],\n",
       "       [ 0,  0, 69,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0, 76,  0,  0,  1,  0,  0,  0],\n",
       "       [ 0,  0,  1,  0, 50,  2,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0, 70,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  1,  0,  1, 74,  1,  0,  0],\n",
       "       [ 0,  0,  0,  0,  3,  0,  0, 80,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0, 73,  0],\n",
       "       [ 2,  1,  1,  2,  1,  1,  0,  0,  0, 61]], dtype=int64)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf_mat=confusion_matrix(y_test_values, predictions, labels=range(10))\n",
    "conf_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sns' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[101], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(CLASSES_MAP\u001b[38;5;241m.\u001b[39mkeys())\n\u001b[0;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m6\u001b[39m))\n\u001b[1;32m----> 4\u001b[0m heatmap \u001b[38;5;241m=\u001b[39m \u001b[43msns\u001b[49m\u001b[38;5;241m.\u001b[39mheatmap(conf_mat, annot\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, fmt\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124md\u001b[39m\u001b[38;5;124m\"\u001b[39m, cmap\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBlues\u001b[39m\u001b[38;5;124m\"\u001b[39m, cbar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Set the custom class labels\u001b[39;00m\n\u001b[0;32m      7\u001b[0m heatmap\u001b[38;5;241m.\u001b[39mset_xticklabels(classes)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'sns' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "classes = list(CLASSES_MAP.keys())\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "heatmap = sns.heatmap(conf_mat, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False)\n",
    "\n",
    "# Set the custom class labels\n",
    "heatmap.set_xticklabels(classes)\n",
    "heatmap.set_yticklabels(classes)\n",
    "\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save model to disk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### serialize model to JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_DIR = \"./model/\"\n",
    "MODEL_JSON = \"./model/model.json\"\n",
    "MODEL_H5 = \"./model/model.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_json = model.to_json()\n",
    "with open(MODEL_JSON, \"w\") as json_file:\n",
    "    json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### serialize weights to HDF5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'MODEL_H5' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model\u001b[38;5;241m.\u001b[39msave_weights(\u001b[43mMODEL_H5\u001b[49m)\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSaved model to disk\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'MODEL_H5' is not defined"
     ]
    }
   ],
   "source": [
    "model.save_weights(MODEL_H5)\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n"
     ]
    }
   ],
   "source": [
    "json_file = open('./model/model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"./model/model.h5\")\n",
    "print(\"Loaded model from disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision(y_true, y_pred):\n",
    "    '''Calculates the precision, a metric for multi-label classification of\n",
    "    how many selected items are relevant.\n",
    "    '''\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "\n",
    "def recall(y_true, y_pred):\n",
    "    '''Calculates the recall, a metric for multi-label classification of\n",
    "    how many relevant items are selected.\n",
    "    '''\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "\n",
    "def fbeta_score(y_true, y_pred, beta=1):\n",
    "    '''Calculates the F score, the weighted harmonic mean of precision and recall.\n",
    "    This is useful for multi-label classification, where input samples can be\n",
    "    classified as sets of labels. By only using accuracy (precision) a model\n",
    "    would achieve a perfect score by simply assigning every class to every\n",
    "    input. In order to avoid this, a metric should penalize incorrect class\n",
    "    assignments as well (recall). The F-beta score (ranged from 0.0 to 1.0)\n",
    "    computes this, as a weighted mean of the proportion of correct class\n",
    "    assignments vs. the proportion of incorrect class assignments.\n",
    "    With beta = 1, this is equivalent to a F-measure. With beta < 1, assigning\n",
    "    correct classes becomes more important, and with beta > 1 the metric is\n",
    "    instead weighted towards penalizing incorrect class assignments.\n",
    "    '''\n",
    "    if beta < 0:\n",
    "        raise ValueError('The lowest choosable beta is zero (only precision).')\n",
    "        \n",
    "    # If there are no true positives, fix the F score at 0 like sklearn.\n",
    "    if K.sum(K.round(K.clip(y_true, 0, 1))) == 0:\n",
    "        return 0.0\n",
    "\n",
    "    p = precision(y_true, y_pred)\n",
    "    r = recall(y_true, y_pred)\n",
    "    bb = beta ** 2\n",
    "    fbeta_score = (1 + bb) * (p * r) / (bb * p + r + K.epsilon())\n",
    "    return fbeta_score\n",
    "\n",
    "\n",
    "def fmeasure(y_true, y_pred):\n",
    "    '''Calculates the f-measure, the harmonic mean of precision and recall.\n",
    "    '''\n",
    "    return fbeta_score(y_true, y_pred, beta=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model.compile(\n",
    "\toptimizer=\"Adam\",\n",
    "\tloss=\"categorical_crossentropy\",\n",
    "\tmetrics=['accuracy', precision, recall,fmeasure])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import IPython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "44100\n",
      "1/1 [==============================] - 0s 306ms/step\n",
      "[1]\n",
      "am\n",
      "44100\n",
      "88200\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "[5]\n",
      "dm\n",
      "88200\n",
      "132300\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "[6]\n",
      "e\n",
      "132300\n",
      "176400\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "[5]\n",
      "dm\n"
     ]
    }
   ],
   "source": [
    "y, sr = librosa.load('./data/mainPrediction/audio.wav')\n",
    "total_duration = librosa.get_duration(y=y, sr=sr)\n",
    "iterate = math.floor(total_duration/2)\n",
    "for i in range(0, iterate):\n",
    "    start_time = i*2\n",
    "    start_index = int(start_time * sr)\n",
    "    end_index = int(start_index + (sr*2))\n",
    "    print(start_index)\n",
    "    print(end_index)\n",
    "    segment = y[start_index:end_index]\n",
    "    ps = librosa.feature.melspectrogram(y=segment, sr=sr)\n",
    "    ps = np.array(ps.reshape(1, 128, 87, 1))\n",
    "    predicted = loaded_model.predict(ps)\n",
    "    predicted = np.argmax(predicted, axis=1)\n",
    "    print(predicted)\n",
    "    print(CLASSES[predicted[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y, sr = librosa.load('./data/mainPrediction/audio.wav',duration=2)\n",
    "ps = librosa.feature.melspectrogram(y=y, sr=sr)\n",
    "ps.shape\n",
    "ps= np.array(ps.reshape(1,128,87,1))\n",
    "ps.shape\n",
    "\n",
    "predicted = loaded_model.predict(ps)\n",
    "predicted = np.argmax(predicted,axis=1)\n",
    "predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in predicted:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASSES[predicted[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data Augmentation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import soundfile as sf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_augmentation_count(df):\n",
    "    return df['augmentation'].value_counts()\n",
    "\n",
    "@df_info\n",
    "def augment_data(df, kind='time', rate=1.07):\n",
    "    if kind == 'time':\n",
    "        df['y'] = df['y'].map(lambda y:librosa.effects.time_stretch(y, rate=rate))\n",
    "        new_path = 'speed_' + str(int(rate*100))\n",
    "    elif kind == 'pitch':\n",
    "        df['y'] = df.apply(lambda row:librosa.effects.pitch_shift(row['y'], sr=row['sr'], n_steps=rate), axis=1)\n",
    "        new_path = 'pitch_' + str(int(rate*100))\n",
    "    df['file_path'] = df.apply(lambda row: row['class_name']+'/'+new_path\\\n",
    "                                                      +\"/\"+row['file_name'], axis=1)\n",
    "    for class_name in CLASSES:\n",
    "        directory = os.path.join(DATA_DIR_AUGMENTED,class_name,new_path)\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "    path_exists_mask =  df['file_path'].map(lambda x: not os.path.exists(os.path.join(DATA_DIR_AUGMENTED, x)))\n",
    "    # df[path_exists_mask].apply(lambda row: librosa.output.write_wav(os.path.join(DATA_DIR_AUGMENTED, row['file_path']),row['y'], row['sr']), axis=1)\n",
    "    df[path_exists_mask].apply(lambda row: sf.write(os.path.join(DATA_DIR_AUGMENTED, row['file_path']),row['y'], row['sr']), axis=1)\n",
    "    \n",
    "   \n",
    "    df['spectrogram'] = df.apply(lambda row: librosa.feature.melspectrogram(y=row['y'], \\\n",
    "                                                sr=row['sr']),axis=1)\n",
    "    df['augmentation'] = new_path\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df_raw = pd.read_pickle(os.path.join(METADATA_DIR_RAW, 'data.pkl'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After applying augment_data, shape of df = (2000, 9)\n",
      "Columns of df are Index(['file_path', 'file_name', 'class_name', 'class_ID', 'y', 'sr',\n",
      "       'spectrogram', 'shape', 'augmentation'],\n",
      "      dtype='object')\n",
      "\n",
      "After applying augment_data, shape of df = (2000, 9)\n",
      "Columns of df are Index(['file_path', 'file_name', 'class_name', 'class_ID', 'y', 'sr',\n",
      "       'spectrogram', 'shape', 'augmentation'],\n",
      "      dtype='object')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### 1. Vary Time\n",
    "data_df_time_inc = augment_data(data_df_raw.copy(), kind='time', rate=1.07)\n",
    "                    \n",
    "\n",
    "data_df_time_dec = augment_data(data_df_raw.copy(), kind='time', rate=0.81)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After applying augment_data, shape of df = (2000, 9)\n",
      "Columns of df are Index(['file_path', 'file_name', 'class_name', 'class_ID', 'y', 'sr',\n",
      "       'spectrogram', 'shape', 'augmentation'],\n",
      "      dtype='object')\n",
      "\n",
      "After applying augment_data, shape of df = (2000, 9)\n",
      "Columns of df are Index(['file_path', 'file_name', 'class_name', 'class_ID', 'y', 'sr',\n",
      "       'spectrogram', 'shape', 'augmentation'],\n",
      "      dtype='object')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### 2. Vary pitch\n",
    "data_df_shift_20 = augment_data(data_df_raw.copy(), kind='pitch', rate=2.5)\n",
    "\n",
    "data_df_shift_25 = augment_data(data_df_raw.copy(), kind='pitch', rate=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### Create Augmented Metada\n",
    "data_df_raw['augmentation'] = 'None'\n",
    "data_df_augmented_raw = pd.concat([data_df_raw, data_df_time_inc, data_df_time_dec, data_df_shift_20, data_df_shift_25], axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After applying add_shape, shape of df = (10000, 9)\n",
      "Columns of df are Index(['file_path', 'file_name', 'class_name', 'class_ID', 'y', 'sr',\n",
      "       'spectrogram', 'shape', 'augmentation'],\n",
      "      dtype='object')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_df_augmented_raw = data_df_augmented_raw.pipe(add_shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None         2000\n",
      "speed_107    2000\n",
      "speed_81     2000\n",
      "pitch_250    2000\n",
      "pitch_200    2000\n",
      "Name: augmentation, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(get_augmentation_count(data_df_augmented_raw))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After applying get_count, shape of df = (10,)\n",
      "Columns of df are Index(['file_path', 'file_name', 'class_name', 'class_ID', 'y', 'sr',\n",
      "       'spectrogram', 'shape', 'augmentation'],\n",
      "      dtype='object')\n",
      "\n",
      "a     1000\n",
      "am    1000\n",
      "bm    1000\n",
      "c     1000\n",
      "d     1000\n",
      "dm    1000\n",
      "e     1000\n",
      "em    1000\n",
      "f     1000\n",
      "g     1000\n",
      "Name: class_name, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(get_count(data_df_augmented_raw))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_path</th>\n",
       "      <th>file_name</th>\n",
       "      <th>class_name</th>\n",
       "      <th>class_ID</th>\n",
       "      <th>y</th>\n",
       "      <th>sr</th>\n",
       "      <th>spectrogram</th>\n",
       "      <th>shape</th>\n",
       "      <th>augmentation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a\\a1.wav</td>\n",
       "      <td>a1.wav</td>\n",
       "      <td>a</td>\n",
       "      <td>0</td>\n",
       "      <td>[-0.00044090126, -0.0005725771, -0.0003972128,...</td>\n",
       "      <td>22050</td>\n",
       "      <td>[[1.4596097e-05, 0.00024260355, 0.00096791255,...</td>\n",
       "      <td>(128, 52)</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a\\a10.wav</td>\n",
       "      <td>a10.wav</td>\n",
       "      <td>a</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.025644582, 0.03873189, 0.034305602, 0.03391...</td>\n",
       "      <td>22050</td>\n",
       "      <td>[[0.013701358, 0.003172148, 0.0015002444, 0.00...</td>\n",
       "      <td>(128, 66)</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a\\a100.wav</td>\n",
       "      <td>a100.wav</td>\n",
       "      <td>a</td>\n",
       "      <td>0</td>\n",
       "      <td>[-0.00018296344, -0.0002981358, -0.0002974281,...</td>\n",
       "      <td>22050</td>\n",
       "      <td>[[0.00030085637, 0.00028734427, 0.00024939657,...</td>\n",
       "      <td>(128, 81)</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a\\a101.wav</td>\n",
       "      <td>a101.wav</td>\n",
       "      <td>a</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0004918799, 0.00016076537, -0.00018280663, ...</td>\n",
       "      <td>22050</td>\n",
       "      <td>[[0.0050224112, 0.005019857, 0.004343026, 0.00...</td>\n",
       "      <td>(128, 71)</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a\\a102.wav</td>\n",
       "      <td>a102.wav</td>\n",
       "      <td>a</td>\n",
       "      <td>0</td>\n",
       "      <td>[-0.0071322983, -0.010516543, -0.008813906, -0...</td>\n",
       "      <td>22050</td>\n",
       "      <td>[[0.004694343, 0.004831752, 0.004024386, 0.004...</td>\n",
       "      <td>(128, 77)</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    file_path file_name class_name  class_ID  \\\n",
       "0    a\\a1.wav    a1.wav          a         0   \n",
       "1   a\\a10.wav   a10.wav          a         0   \n",
       "2  a\\a100.wav  a100.wav          a         0   \n",
       "3  a\\a101.wav  a101.wav          a         0   \n",
       "4  a\\a102.wav  a102.wav          a         0   \n",
       "\n",
       "                                                   y     sr  \\\n",
       "0  [-0.00044090126, -0.0005725771, -0.0003972128,...  22050   \n",
       "1  [0.025644582, 0.03873189, 0.034305602, 0.03391...  22050   \n",
       "2  [-0.00018296344, -0.0002981358, -0.0002974281,...  22050   \n",
       "3  [0.0004918799, 0.00016076537, -0.00018280663, ...  22050   \n",
       "4  [-0.0071322983, -0.010516543, -0.008813906, -0...  22050   \n",
       "\n",
       "                                         spectrogram      shape augmentation  \n",
       "0  [[1.4596097e-05, 0.00024260355, 0.00096791255,...  (128, 52)         None  \n",
       "1  [[0.013701358, 0.003172148, 0.0015002444, 0.00...  (128, 66)         None  \n",
       "2  [[0.00030085637, 0.00028734427, 0.00024939657,...  (128, 81)         None  \n",
       "3  [[0.0050224112, 0.005019857, 0.004343026, 0.00...  (128, 71)         None  \n",
       "4  [[0.004694343, 0.004831752, 0.004024386, 0.004...  (128, 77)         None  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df_augmented_raw.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Save augmented raw data\n",
    "data_df_augmented_raw.to_csv(os.path.join(METADATA_DIR_AUGMENTED_RAW, 'data.csv'), index=False)\n",
    "data_df_augmented_raw.to_pickle(os.path.join(METADATA_DIR_AUGMENTED_RAW, 'data.pkl'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Process and save processed augmented data\n",
    "data_df_augmented_raw = pd.read_pickle(os.path.join(METADATA_DIR_AUGMENTED_RAW, 'data.pkl'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maintain same shape\n",
    "@df_info\n",
    "def clean_shape(df):\n",
    "    max_shape = df['spectrogram'].map(lambda x: x.shape).value_counts().index[0]\n",
    "    print(f\"The most frequent shape is {max_shape}\")\n",
    "    df['shape'] = df['spectrogram'].map(lambda x: x.shape)\n",
    "    df = df[df['shape']==max_shape]\n",
    "    df.drop(columns='shape', inplace=True)\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    return df\n",
    "\n",
    "@df_info\n",
    "def process_augmented(df):\n",
    "    df = (df.pipe(clean_shape)\n",
    "            .pipe(over_sample)\n",
    "    )\n",
    "    df = df[['spectrogram','class_ID', 'class_name', 'augmentation']]\n",
    "    \n",
    "    return df\n",
    "\n",
    "#Over sampling data\n",
    "@df_info\n",
    "def over_sample(df):\n",
    "    oversample = RandomOverSampler(sampling_strategy='auto')\n",
    "    X, y = df[['spectrogram', 'augmentation']].values, df['class_ID'].values\n",
    "#     X = X.reshape(-1, 1)\n",
    "    X, y = oversample.fit_resample(X, y)\n",
    "    df = pd.DataFrame()\n",
    "    df['spectrogram'] = pd.Series([np.array(x[0]) for x in X])\n",
    "    df['augmentation'] = pd.Series([np.array(x[1]) for x in X])\n",
    "    df['augmentation'] = df['augmentation'].map(lambda x: str(x))\n",
    "    df['class_ID'] = pd.Series(y)\n",
    "    df['class_name'] = df['class_ID'].map(lambda x: get_class(x))\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most frequent shape is (128, 87)\n",
      "After applying clean_shape, shape of df = (1931, 8)\n",
      "Columns of df are Index(['file_path', 'file_name', 'class_name', 'class_ID', 'y', 'sr',\n",
      "       'spectrogram', 'shape', 'augmentation'],\n",
      "      dtype='object')\n",
      "\n",
      "After applying over_sample, shape of df = (3460, 4)\n",
      "Columns of df are Index(['file_path', 'file_name', 'class_name', 'class_ID', 'y', 'sr',\n",
      "       'spectrogram', 'augmentation'],\n",
      "      dtype='object')\n",
      "\n",
      "After applying process_augmented, shape of df = (3460, 4)\n",
      "Columns of df are Index(['file_path', 'file_name', 'class_name', 'class_ID', 'y', 'sr',\n",
      "       'spectrogram', 'shape', 'augmentation'],\n",
      "      dtype='object')\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shiva Kumar\\AppData\\Local\\Temp\\ipykernel_26788\\1976268698.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.drop(columns='shape', inplace=True)\n"
     ]
    }
   ],
   "source": [
    "data_df_augmented_processed = process_augmented(data_df_augmented_raw)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df_augmented_processed.to_csv(os.path.join(METADATA_DIR_AUGMENTED_PROCESSED, 'data.csv'), index=False)\n",
    "data_df_augmented_processed.to_pickle(os.path.join(METADATA_DIR_AUGMENTED_PROCESSED, 'data.pkl'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After applying get_count, shape of df = (10,)\n",
      "Columns of df are Index(['spectrogram', 'class_ID', 'class_name', 'augmentation'], dtype='object')\n",
      "\n",
      "a     346\n",
      "am    346\n",
      "bm    346\n",
      "c     346\n",
      "d     346\n",
      "dm    346\n",
      "e     346\n",
      "em    346\n",
      "f     346\n",
      "g     346\n",
      "Name: class_name, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(get_count(data_df_augmented_processed))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None         1137\n",
      "pitch_250    1102\n",
      "pitch_200    1059\n",
      "speed_81      162\n",
      "Name: augmentation, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(get_augmentation_count(data_df_augmented_processed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load processed augmented data\n",
    "dataset = pd.read_pickle(os.path.join(METADATA_DIR_AUGMENTED_PROCESSED, 'data.pkl'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples:  3460\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of samples: \", len(dataset))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spectrogram     [[0.0047523906, 0.0045139925, 0.0045696595, 0....\n",
       "class_ID                                                        0\n",
       "class_name                                                      a\n",
       "augmentation                                                 None\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.iloc[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 87)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['spectrogram'].iloc[0].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples is 2768\n",
      "Number of testing samples is 692\n",
      "                                            spectrogram  class_ID class_name  \\\n",
      "665   [[0.004291551, 0.005132644, 0.0040251277, 0.00...         0          a   \n",
      "410   [[0.0074316473, 0.0075097657, 0.0061198766, 0....         6          e   \n",
      "1894  [[0.0072418978, 0.008705427, 0.006059195, 0.00...         9          g   \n",
      "1575  [[0.026117027, 0.012626264, 0.005709873, 0.004...         4          d   \n",
      "2419  [[0.0005311791, 0.0007006633, 0.00038866603, 0...         2         bm   \n",
      "578   [[0.0069079865, 0.007465108, 0.014432898, 0.02...         9          g   \n",
      "602   [[0.010945355, 0.006587258, 0.005281261, 0.005...         9          g   \n",
      "192   [[0.20456532, 0.062573306, 0.005481981, 0.0056...         3          c   \n",
      "3312  [[0.000652256, 0.00078245724, 0.0013207349, 0....         8          f   \n",
      "299   [[0.00043750665, 0.00044024937, 0.00025882272,...         4          d   \n",
      "\n",
      "     augmentation  \n",
      "665     pitch_250  \n",
      "410          None  \n",
      "1894    pitch_200  \n",
      "1575    pitch_200  \n",
      "2419    pitch_200  \n",
      "578          None  \n",
      "602          None  \n",
      "192          None  \n",
      "3312         None  \n",
      "299          None  \n",
      "                                          spectrogram  class_ID class_name  \\\n",
      "1   [[0.007935312, 0.009195907, 0.0041631414, 0.00...         0          a   \n",
      "4   [[0.00042518272, 0.00048722717, 0.0003344478, ...         0          a   \n",
      "11  [[0.000654014, 0.0006707842, 0.00063801324, 0....         0          a   \n",
      "16  [[0.00030390857, 0.00036621877, 0.00035638362,...         0          a   \n",
      "19  [[0.00036142257, 0.00047406525, 0.0007132279, ...         0          a   \n",
      "21  [[8.226129e-05, 6.553833e-05, 0.00025210707, 0...         0          a   \n",
      "34  [[0.009080363, 0.008830369, 0.01579431, 0.0118...         1         am   \n",
      "35  [[0.006813914, 0.008772482, 0.006955781, 0.006...         1         am   \n",
      "36  [[0.0059204083, 0.006823105, 0.008190805, 0.00...         1         am   \n",
      "38  [[0.01223254, 0.006064369, 0.0062395367, 0.006...         1         am   \n",
      "\n",
      "   augmentation  \n",
      "1          None  \n",
      "4          None  \n",
      "11         None  \n",
      "16         None  \n",
      "19         None  \n",
      "21         None  \n",
      "34         None  \n",
      "35         None  \n",
      "36         None  \n",
      "38         None  \n"
     ]
    }
   ],
   "source": [
    "### Splitting into train and test\n",
    "np.random.seed(42)\n",
    "sample = np.random.choice(dataset.index, size=int(len(dataset)*0.8), replace=False)\n",
    "train_data, test_data = dataset.iloc[sample], dataset.drop(sample)\n",
    "\n",
    "print(\"Number of training samples is\", len(train_data))\n",
    "print(\"Number of testing samples is\", len(test_data))\n",
    "print(train_data[:10])\n",
    "print(test_data[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.2915512e-03, 5.1326440e-03, 4.0251277e-03, ..., 4.0479349e-03,\n",
       "        3.4223055e-03, 2.2110704e-03],\n",
       "       [1.1900977e-03, 8.8806730e-04, 3.7031446e-04, ..., 1.3748504e-04,\n",
       "        2.8961780e-04, 1.3347667e-04],\n",
       "       [5.1884464e-04, 2.7734721e-03, 2.2764422e-03, ..., 4.4160782e-04,\n",
       "        2.0541305e-04, 1.0287375e-04],\n",
       "       ...,\n",
       "       [4.6952437e-03, 8.5646939e-03, 3.0891607e-03, ..., 4.0243817e-06,\n",
       "        3.1428601e-06, 1.3520666e-06],\n",
       "       [1.5282539e-03, 3.9637205e-03, 2.8330726e-03, ..., 1.9065000e-06,\n",
       "        1.2762315e-06, 4.0001305e-07],\n",
       "       [1.3269918e-04, 1.8355910e-04, 7.4094212e-05, ..., 1.4629715e-07,\n",
       "        7.6093819e-08, 6.0915298e-08]], dtype=float32)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['spectrogram'].iloc[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spectrogram     [[0.004291551, 0.005132644, 0.0040251277, 0.00...\n",
      "class_ID                                                        0\n",
      "class_name                                                      a\n",
      "augmentation                                            pitch_250\n",
      "Name: 665, dtype: object\n",
      "(128, 87)\n",
      "0.005132644\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(train_data.iloc[0])\n",
    "print(train_data.iloc[0][0].shape)   #shape of input image\n",
    "print(train_data.iloc[0][0][0][1])\n",
    "print(train_data.iloc[0][1])    #output class id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "665     [[0.004291551, 0.005132644, 0.0040251277, 0.00...\n",
      "410     [[0.0074316473, 0.0075097657, 0.0061198766, 0....\n",
      "1894    [[0.0072418978, 0.008705427, 0.006059195, 0.00...\n",
      "1575    [[0.026117027, 0.012626264, 0.005709873, 0.004...\n",
      "2419    [[0.0005311791, 0.0007006633, 0.00038866603, 0...\n",
      "578     [[0.0069079865, 0.007465108, 0.014432898, 0.02...\n",
      "602     [[0.010945355, 0.006587258, 0.005281261, 0.005...\n",
      "192     [[0.20456532, 0.062573306, 0.005481981, 0.0056...\n",
      "3312    [[0.000652256, 0.00078245724, 0.0013207349, 0....\n",
      "299     [[0.00043750665, 0.00044024937, 0.00025882272,...\n",
      "Name: spectrogram, dtype: object\n",
      "665     0\n",
      "410     6\n",
      "1894    9\n",
      "1575    4\n",
      "2419    2\n",
      "578     9\n",
      "602     9\n",
      "192     3\n",
      "3312    8\n",
      "299     4\n",
      "Name: class_ID, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "## Splitting the data into features (X) and targets (y)\n",
    "\n",
    "X_train = train_data['spectrogram']\n",
    "y_train = train_data['class_ID']\n",
    "X_test = test_data['spectrogram']\n",
    "y_test = test_data['class_ID']\n",
    "\n",
    "print(X_train[:10])\n",
    "print(y_train[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Reshape for CNN input\n",
    "X_train = np.array([x.reshape( (128, 87, 1) ) for x in X_train])\n",
    "X_test = np.array([x.reshape( (128, 87, 1) ) for x in X_test])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 87, 1)\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(X_train[0].shape)\n",
    "print(y_train[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "### One-Hot encoding for classes\n",
    "y_train = np.array(keras.utils.to_categorical(y_train, 10))\n",
    "y_test_values=y_test\n",
    "y_test = np.array(keras.utils.to_categorical(y_test, 10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(y_train[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 124, 83, 24)       624       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 31, 41, 24)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " activation (Activation)     (None, 31, 41, 24)        0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 27, 37, 48)        28848     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 6, 18, 48)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 6, 18, 48)         0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 2, 14, 48)         57648     \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 2, 14, 48)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 1344)              0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 1344)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                86080     \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 64)                0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                650       \n",
      "                                                                 \n",
      " activation_4 (Activation)   (None, 10)                0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 173,850\n",
      "Trainable params: 173,850\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "### Model\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "139/139 [==============================] - 12s 78ms/step - loss: 0.0680 - accuracy: 0.9852 - precision: 0.9860 - recall: 0.9849 - fmeasure: 0.9854 - val_loss: 0.7628 - val_accuracy: 0.9653 - val_precision: 0.9698 - val_recall: 0.9657 - val_fmeasure: 0.9677\n",
      "Epoch 2/70\n",
      "139/139 [==============================] - 10s 75ms/step - loss: 0.1336 - accuracy: 0.9801 - precision: 0.9800 - recall: 0.9793 - fmeasure: 0.9797 - val_loss: 0.6117 - val_accuracy: 0.9682 - val_precision: 0.9729 - val_recall: 0.9671 - val_fmeasure: 0.9698\n",
      "Epoch 3/70\n",
      "139/139 [==============================] - 11s 76ms/step - loss: 0.2399 - accuracy: 0.9693 - precision: 0.9698 - recall: 0.9694 - fmeasure: 0.9696 - val_loss: 0.5490 - val_accuracy: 0.9393 - val_precision: 0.9510 - val_recall: 0.9386 - val_fmeasure: 0.9445\n",
      "Epoch 4/70\n",
      "139/139 [==============================] - 10s 74ms/step - loss: 0.2823 - accuracy: 0.9682 - precision: 0.9714 - recall: 0.9655 - fmeasure: 0.9684 - val_loss: 0.5488 - val_accuracy: 0.9682 - val_precision: 0.9733 - val_recall: 0.9676 - val_fmeasure: 0.9703\n",
      "Epoch 5/70\n",
      "139/139 [==============================] - 12s 83ms/step - loss: 0.1742 - accuracy: 0.9769 - precision: 0.9787 - recall: 0.9766 - fmeasure: 0.9776 - val_loss: 0.6419 - val_accuracy: 0.9827 - val_precision: 0.9842 - val_recall: 0.9814 - val_fmeasure: 0.9828\n",
      "Epoch 6/70\n",
      "139/139 [==============================] - 11s 78ms/step - loss: 0.0664 - accuracy: 0.9877 - precision: 0.9881 - recall: 0.9874 - fmeasure: 0.9878 - val_loss: 0.3548 - val_accuracy: 0.9711 - val_precision: 0.9713 - val_recall: 0.9686 - val_fmeasure: 0.9699\n",
      "Epoch 7/70\n",
      "139/139 [==============================] - 11s 78ms/step - loss: 0.0624 - accuracy: 0.9877 - precision: 0.9879 - recall: 0.9862 - fmeasure: 0.9870 - val_loss: 0.1874 - val_accuracy: 0.9783 - val_precision: 0.9798 - val_recall: 0.9771 - val_fmeasure: 0.9784\n",
      "Epoch 8/70\n",
      "139/139 [==============================] - 11s 79ms/step - loss: 0.0489 - accuracy: 0.9870 - precision: 0.9885 - recall: 0.9867 - fmeasure: 0.9876 - val_loss: 0.2148 - val_accuracy: 0.9711 - val_precision: 0.9741 - val_recall: 0.9686 - val_fmeasure: 0.9712\n",
      "Epoch 9/70\n",
      "139/139 [==============================] - 10s 75ms/step - loss: 0.2795 - accuracy: 0.9765 - precision: 0.9787 - recall: 0.9755 - fmeasure: 0.9771 - val_loss: 0.5988 - val_accuracy: 0.9711 - val_precision: 0.9742 - val_recall: 0.9700 - val_fmeasure: 0.9720\n",
      "Epoch 10/70\n",
      "139/139 [==============================] - 11s 76ms/step - loss: 0.1648 - accuracy: 0.9798 - precision: 0.9804 - recall: 0.9793 - fmeasure: 0.9798 - val_loss: 0.7683 - val_accuracy: 0.9668 - val_precision: 0.9671 - val_recall: 0.9657 - val_fmeasure: 0.9664\n",
      "Epoch 11/70\n",
      "139/139 [==============================] - 11s 82ms/step - loss: 0.1536 - accuracy: 0.9725 - precision: 0.9743 - recall: 0.9701 - fmeasure: 0.9722 - val_loss: 0.0819 - val_accuracy: 0.9754 - val_precision: 0.9770 - val_recall: 0.9729 - val_fmeasure: 0.9749\n",
      "Epoch 12/70\n",
      "139/139 [==============================] - 11s 79ms/step - loss: 0.1029 - accuracy: 0.9830 - precision: 0.9838 - recall: 0.9824 - fmeasure: 0.9831 - val_loss: 0.3232 - val_accuracy: 0.9653 - val_precision: 0.9671 - val_recall: 0.9657 - val_fmeasure: 0.9664\n",
      "Epoch 13/70\n",
      "139/139 [==============================] - 11s 77ms/step - loss: 0.0423 - accuracy: 0.9877 - precision: 0.9892 - recall: 0.9874 - fmeasure: 0.9883 - val_loss: 0.2353 - val_accuracy: 0.9725 - val_precision: 0.9741 - val_recall: 0.9714 - val_fmeasure: 0.9727\n",
      "Epoch 14/70\n",
      "139/139 [==============================] - 11s 79ms/step - loss: 0.0701 - accuracy: 0.9874 - precision: 0.9888 - recall: 0.9874 - fmeasure: 0.9881 - val_loss: 0.3089 - val_accuracy: 0.9812 - val_precision: 0.9814 - val_recall: 0.9786 - val_fmeasure: 0.9799\n",
      "Epoch 15/70\n",
      "139/139 [==============================] - 11s 83ms/step - loss: 0.2073 - accuracy: 0.9837 - precision: 0.9856 - recall: 0.9831 - fmeasure: 0.9843 - val_loss: 1.0913 - val_accuracy: 0.9581 - val_precision: 0.9608 - val_recall: 0.9571 - val_fmeasure: 0.9589\n",
      "Epoch 16/70\n",
      "139/139 [==============================] - 11s 82ms/step - loss: 0.6007 - accuracy: 0.9617 - precision: 0.9669 - recall: 0.9594 - fmeasure: 0.9630 - val_loss: 0.7054 - val_accuracy: 0.9581 - val_precision: 0.9676 - val_recall: 0.9586 - val_fmeasure: 0.9628\n",
      "Epoch 17/70\n",
      "139/139 [==============================] - 11s 80ms/step - loss: 0.3332 - accuracy: 0.9660 - precision: 0.9729 - recall: 0.9646 - fmeasure: 0.9686 - val_loss: 0.1394 - val_accuracy: 0.9682 - val_precision: 0.9726 - val_recall: 0.9671 - val_fmeasure: 0.9698\n",
      "Epoch 18/70\n",
      "139/139 [==============================] - 11s 81ms/step - loss: 0.0738 - accuracy: 0.9859 - precision: 0.9874 - recall: 0.9845 - fmeasure: 0.9859 - val_loss: 0.1564 - val_accuracy: 0.9624 - val_precision: 0.9657 - val_recall: 0.9629 - val_fmeasure: 0.9642\n",
      "Epoch 19/70\n",
      "139/139 [==============================] - 11s 79ms/step - loss: 0.0371 - accuracy: 0.9874 - precision: 0.9881 - recall: 0.9874 - fmeasure: 0.9877 - val_loss: 0.1661 - val_accuracy: 0.9697 - val_precision: 0.9714 - val_recall: 0.9700 - val_fmeasure: 0.9707\n",
      "Epoch 20/70\n",
      "139/139 [==============================] - 11s 78ms/step - loss: 0.0685 - accuracy: 0.9874 - precision: 0.9881 - recall: 0.9867 - fmeasure: 0.9874 - val_loss: 0.4514 - val_accuracy: 0.9754 - val_precision: 0.9827 - val_recall: 0.9743 - val_fmeasure: 0.9783\n",
      "Epoch 21/70\n",
      "139/139 [==============================] - 11s 78ms/step - loss: 0.0890 - accuracy: 0.9877 - precision: 0.9885 - recall: 0.9867 - fmeasure: 0.9876 - val_loss: 0.1567 - val_accuracy: 0.9711 - val_precision: 0.9756 - val_recall: 0.9700 - val_fmeasure: 0.9727\n",
      "Epoch 22/70\n",
      "139/139 [==============================] - 11s 76ms/step - loss: 0.1109 - accuracy: 0.9809 - precision: 0.9817 - recall: 0.9802 - fmeasure: 0.9809 - val_loss: 0.7342 - val_accuracy: 0.9668 - val_precision: 0.9671 - val_recall: 0.9671 - val_fmeasure: 0.9671\n",
      "Epoch 23/70\n",
      "139/139 [==============================] - 11s 80ms/step - loss: 0.0797 - accuracy: 0.9855 - precision: 0.9870 - recall: 0.9853 - fmeasure: 0.9861 - val_loss: 0.6525 - val_accuracy: 0.9682 - val_precision: 0.9698 - val_recall: 0.9671 - val_fmeasure: 0.9684\n",
      "Epoch 24/70\n",
      "139/139 [==============================] - 11s 78ms/step - loss: 0.0347 - accuracy: 0.9931 - precision: 0.9942 - recall: 0.9932 - fmeasure: 0.9937 - val_loss: 0.4964 - val_accuracy: 0.9754 - val_precision: 0.9839 - val_recall: 0.9743 - val_fmeasure: 0.9789\n",
      "Epoch 25/70\n",
      "139/139 [==============================] - 11s 79ms/step - loss: 0.7491 - accuracy: 0.9899 - precision: 0.9910 - recall: 0.9899 - fmeasure: 0.9905 - val_loss: 0.3252 - val_accuracy: 0.9494 - val_precision: 0.9595 - val_recall: 0.9500 - val_fmeasure: 0.9546\n",
      "Epoch 26/70\n",
      "139/139 [==============================] - 11s 79ms/step - loss: 0.4412 - accuracy: 0.9498 - precision: 0.9588 - recall: 0.9468 - fmeasure: 0.9526 - val_loss: 0.2012 - val_accuracy: 0.9552 - val_precision: 0.9665 - val_recall: 0.9543 - val_fmeasure: 0.9602\n",
      "Epoch 27/70\n",
      "139/139 [==============================] - 11s 80ms/step - loss: 0.1425 - accuracy: 0.9751 - precision: 0.9787 - recall: 0.9734 - fmeasure: 0.9760 - val_loss: 0.1627 - val_accuracy: 0.9827 - val_precision: 0.9869 - val_recall: 0.9771 - val_fmeasure: 0.9818\n",
      "Epoch 28/70\n",
      "139/139 [==============================] - 11s 79ms/step - loss: 0.0813 - accuracy: 0.9899 - precision: 0.9899 - recall: 0.9896 - fmeasure: 0.9897 - val_loss: 0.1574 - val_accuracy: 0.9725 - val_precision: 0.9767 - val_recall: 0.9700 - val_fmeasure: 0.9732\n",
      "Epoch 29/70\n",
      "139/139 [==============================] - 11s 81ms/step - loss: 0.0562 - accuracy: 0.9841 - precision: 0.9859 - recall: 0.9831 - fmeasure: 0.9845 - val_loss: 0.1612 - val_accuracy: 0.9798 - val_precision: 0.9827 - val_recall: 0.9786 - val_fmeasure: 0.9806\n",
      "Epoch 30/70\n",
      "139/139 [==============================] - 11s 79ms/step - loss: 0.1314 - accuracy: 0.9895 - precision: 0.9903 - recall: 0.9888 - fmeasure: 0.9895 - val_loss: 0.1292 - val_accuracy: 0.9841 - val_precision: 0.9857 - val_recall: 0.9829 - val_fmeasure: 0.9842\n",
      "Epoch 31/70\n",
      "139/139 [==============================] - 11s 81ms/step - loss: 0.5475 - accuracy: 0.9451 - precision: 0.9516 - recall: 0.9399 - fmeasure: 0.9456 - val_loss: 0.3158 - val_accuracy: 0.9566 - val_precision: 0.9609 - val_recall: 0.9557 - val_fmeasure: 0.9582\n",
      "Epoch 32/70\n",
      "139/139 [==============================] - 11s 82ms/step - loss: 0.2636 - accuracy: 0.9632 - precision: 0.9674 - recall: 0.9615 - fmeasure: 0.9644 - val_loss: 2.2125 - val_accuracy: 0.9610 - val_precision: 0.9641 - val_recall: 0.9614 - val_fmeasure: 0.9627\n",
      "Epoch 33/70\n",
      "139/139 [==============================] - 11s 79ms/step - loss: 0.2180 - accuracy: 0.9725 - precision: 0.9751 - recall: 0.9716 - fmeasure: 0.9733 - val_loss: 0.3639 - val_accuracy: 0.9682 - val_precision: 0.9726 - val_recall: 0.9686 - val_fmeasure: 0.9705\n",
      "Epoch 34/70\n",
      "139/139 [==============================] - 11s 80ms/step - loss: 0.6732 - accuracy: 0.9678 - precision: 0.9710 - recall: 0.9644 - fmeasure: 0.9676 - val_loss: 0.2236 - val_accuracy: 0.9610 - val_precision: 0.9627 - val_recall: 0.9600 - val_fmeasure: 0.9613\n",
      "Epoch 35/70\n",
      "139/139 [==============================] - 11s 76ms/step - loss: 0.1356 - accuracy: 0.9823 - precision: 0.9849 - recall: 0.9813 - fmeasure: 0.9830 - val_loss: 0.1008 - val_accuracy: 0.9769 - val_precision: 0.9783 - val_recall: 0.9700 - val_fmeasure: 0.9740\n",
      "Epoch 36/70\n",
      "139/139 [==============================] - 11s 80ms/step - loss: 0.1778 - accuracy: 0.9827 - precision: 0.9859 - recall: 0.9824 - fmeasure: 0.9841 - val_loss: 0.1736 - val_accuracy: 0.9812 - val_precision: 0.9827 - val_recall: 0.9800 - val_fmeasure: 0.9813\n",
      "Epoch 37/70\n",
      "139/139 [==============================] - 11s 77ms/step - loss: 0.2097 - accuracy: 0.9834 - precision: 0.9845 - recall: 0.9820 - fmeasure: 0.9832 - val_loss: 0.2603 - val_accuracy: 0.9783 - val_precision: 0.9825 - val_recall: 0.9771 - val_fmeasure: 0.9797\n",
      "Epoch 38/70\n",
      "139/139 [==============================] - 11s 81ms/step - loss: 0.5072 - accuracy: 0.9671 - precision: 0.9677 - recall: 0.9635 - fmeasure: 0.9655 - val_loss: 0.2002 - val_accuracy: 0.9668 - val_precision: 0.9685 - val_recall: 0.9671 - val_fmeasure: 0.9678\n",
      "Epoch 39/70\n",
      "139/139 [==============================] - 11s 79ms/step - loss: 0.0605 - accuracy: 0.9805 - precision: 0.9826 - recall: 0.9795 - fmeasure: 0.9810 - val_loss: 0.1419 - val_accuracy: 0.9697 - val_precision: 0.9726 - val_recall: 0.9657 - val_fmeasure: 0.9690\n",
      "Epoch 40/70\n",
      "139/139 [==============================] - 11s 77ms/step - loss: 0.0469 - accuracy: 0.9902 - precision: 0.9913 - recall: 0.9892 - fmeasure: 0.9902 - val_loss: 0.1230 - val_accuracy: 0.9725 - val_precision: 0.9741 - val_recall: 0.9714 - val_fmeasure: 0.9727\n",
      "Epoch 41/70\n",
      "139/139 [==============================] - 11s 78ms/step - loss: 0.0367 - accuracy: 0.9895 - precision: 0.9906 - recall: 0.9892 - fmeasure: 0.9899 - val_loss: 0.1024 - val_accuracy: 0.9697 - val_precision: 0.9756 - val_recall: 0.9686 - val_fmeasure: 0.9719\n",
      "Epoch 42/70\n",
      "139/139 [==============================] - 11s 80ms/step - loss: 0.0358 - accuracy: 0.9913 - precision: 0.9924 - recall: 0.9896 - fmeasure: 0.9910 - val_loss: 0.0768 - val_accuracy: 0.9798 - val_precision: 0.9814 - val_recall: 0.9786 - val_fmeasure: 0.9799\n",
      "Epoch 43/70\n",
      "139/139 [==============================] - 11s 77ms/step - loss: 0.0117 - accuracy: 0.9975 - precision: 0.9978 - recall: 0.9975 - fmeasure: 0.9977 - val_loss: 0.0999 - val_accuracy: 0.9783 - val_precision: 0.9814 - val_recall: 0.9786 - val_fmeasure: 0.9799\n",
      "Epoch 44/70\n",
      "139/139 [==============================] - 11s 79ms/step - loss: 0.1771 - accuracy: 0.9892 - precision: 0.9895 - recall: 0.9885 - fmeasure: 0.9890 - val_loss: 0.1058 - val_accuracy: 0.9769 - val_precision: 0.9798 - val_recall: 0.9771 - val_fmeasure: 0.9784\n",
      "Epoch 45/70\n",
      "139/139 [==============================] - 11s 77ms/step - loss: 0.0323 - accuracy: 0.9902 - precision: 0.9913 - recall: 0.9903 - fmeasure: 0.9908 - val_loss: 0.1053 - val_accuracy: 0.9725 - val_precision: 0.9756 - val_recall: 0.9729 - val_fmeasure: 0.9742\n",
      "Epoch 46/70\n",
      "139/139 [==============================] - 10s 75ms/step - loss: 0.0728 - accuracy: 0.9859 - precision: 0.9870 - recall: 0.9849 - fmeasure: 0.9859 - val_loss: 0.2184 - val_accuracy: 0.9754 - val_precision: 0.9784 - val_recall: 0.9729 - val_fmeasure: 0.9755\n",
      "Epoch 47/70\n",
      "139/139 [==============================] - 11s 77ms/step - loss: 0.1231 - accuracy: 0.9888 - precision: 0.9892 - recall: 0.9881 - fmeasure: 0.9887 - val_loss: 0.1058 - val_accuracy: 0.9827 - val_precision: 0.9828 - val_recall: 0.9814 - val_fmeasure: 0.9821\n",
      "Epoch 48/70\n",
      "139/139 [==============================] - 11s 77ms/step - loss: 0.0659 - accuracy: 0.9906 - precision: 0.9910 - recall: 0.9906 - fmeasure: 0.9908 - val_loss: 0.1051 - val_accuracy: 0.9870 - val_precision: 0.9886 - val_recall: 0.9829 - val_fmeasure: 0.9856\n",
      "Epoch 49/70\n",
      "139/139 [==============================] - 11s 76ms/step - loss: 0.0467 - accuracy: 0.9877 - precision: 0.9888 - recall: 0.9874 - fmeasure: 0.9881 - val_loss: 0.0681 - val_accuracy: 0.9754 - val_precision: 0.9771 - val_recall: 0.9757 - val_fmeasure: 0.9764\n",
      "Epoch 50/70\n",
      "139/139 [==============================] - 11s 81ms/step - loss: 0.0304 - accuracy: 0.9874 - precision: 0.9888 - recall: 0.9867 - fmeasure: 0.9877 - val_loss: 0.1051 - val_accuracy: 0.9725 - val_precision: 0.9741 - val_recall: 0.9714 - val_fmeasure: 0.9727\n",
      "Epoch 51/70\n",
      "139/139 [==============================] - 11s 78ms/step - loss: 0.0950 - accuracy: 0.9866 - precision: 0.9881 - recall: 0.9860 - fmeasure: 0.9870 - val_loss: 0.1362 - val_accuracy: 0.9682 - val_precision: 0.9714 - val_recall: 0.9686 - val_fmeasure: 0.9699\n",
      "Epoch 52/70\n",
      "139/139 [==============================] - 11s 79ms/step - loss: 0.0601 - accuracy: 0.9906 - precision: 0.9910 - recall: 0.9903 - fmeasure: 0.9906 - val_loss: 0.1789 - val_accuracy: 0.9711 - val_precision: 0.9757 - val_recall: 0.9714 - val_fmeasure: 0.9735\n",
      "Epoch 53/70\n",
      "139/139 [==============================] - 11s 80ms/step - loss: 0.1086 - accuracy: 0.9834 - precision: 0.9852 - recall: 0.9827 - fmeasure: 0.9839 - val_loss: 0.1689 - val_accuracy: 0.9610 - val_precision: 0.9655 - val_recall: 0.9614 - val_fmeasure: 0.9634\n",
      "Epoch 54/70\n",
      "139/139 [==============================] - 11s 76ms/step - loss: 0.0848 - accuracy: 0.9866 - precision: 0.9881 - recall: 0.9867 - fmeasure: 0.9874 - val_loss: 0.1383 - val_accuracy: 0.9754 - val_precision: 0.9798 - val_recall: 0.9757 - val_fmeasure: 0.9777\n",
      "Epoch 55/70\n",
      "139/139 [==============================] - 11s 81ms/step - loss: 0.0395 - accuracy: 0.9906 - precision: 0.9917 - recall: 0.9899 - fmeasure: 0.9908 - val_loss: 0.8625 - val_accuracy: 0.9668 - val_precision: 0.9684 - val_recall: 0.9671 - val_fmeasure: 0.9678\n",
      "Epoch 56/70\n",
      "139/139 [==============================] - 11s 78ms/step - loss: 0.1173 - accuracy: 0.9837 - precision: 0.9856 - recall: 0.9835 - fmeasure: 0.9845 - val_loss: 0.2631 - val_accuracy: 0.9711 - val_precision: 0.9727 - val_recall: 0.9700 - val_fmeasure: 0.9713\n",
      "Epoch 57/70\n",
      "139/139 [==============================] - 11s 80ms/step - loss: 0.0783 - accuracy: 0.9863 - precision: 0.9870 - recall: 0.9856 - fmeasure: 0.9863 - val_loss: 0.2497 - val_accuracy: 0.9740 - val_precision: 0.9757 - val_recall: 0.9743 - val_fmeasure: 0.9750\n",
      "Epoch 58/70\n",
      "139/139 [==============================] - 11s 79ms/step - loss: 0.0487 - accuracy: 0.9902 - precision: 0.9902 - recall: 0.9896 - fmeasure: 0.9899 - val_loss: 0.2967 - val_accuracy: 0.9769 - val_precision: 0.9771 - val_recall: 0.9771 - val_fmeasure: 0.9771\n",
      "Epoch 59/70\n",
      "139/139 [==============================] - 11s 78ms/step - loss: 0.0272 - accuracy: 0.9960 - precision: 0.9960 - recall: 0.9957 - fmeasure: 0.9959 - val_loss: 0.2896 - val_accuracy: 0.9769 - val_precision: 0.9813 - val_recall: 0.9757 - val_fmeasure: 0.9784\n",
      "Epoch 60/70\n",
      "139/139 [==============================] - 11s 82ms/step - loss: 0.0752 - accuracy: 0.9870 - precision: 0.9874 - recall: 0.9871 - fmeasure: 0.9872 - val_loss: 0.3416 - val_accuracy: 0.9538 - val_precision: 0.9570 - val_recall: 0.9543 - val_fmeasure: 0.9556\n",
      "Epoch 61/70\n",
      "139/139 [==============================] - 11s 79ms/step - loss: 0.1800 - accuracy: 0.9758 - precision: 0.9777 - recall: 0.9748 - fmeasure: 0.9762 - val_loss: 0.4530 - val_accuracy: 0.9668 - val_precision: 0.9696 - val_recall: 0.9600 - val_fmeasure: 0.9645\n",
      "Epoch 62/70\n",
      "139/139 [==============================] - 11s 79ms/step - loss: 0.0708 - accuracy: 0.9866 - precision: 0.9867 - recall: 0.9867 - fmeasure: 0.9867 - val_loss: 0.2947 - val_accuracy: 0.9711 - val_precision: 0.9729 - val_recall: 0.9714 - val_fmeasure: 0.9721\n",
      "Epoch 63/70\n",
      "139/139 [==============================] - 11s 80ms/step - loss: 0.0670 - accuracy: 0.9906 - precision: 0.9910 - recall: 0.9892 - fmeasure: 0.9901 - val_loss: 0.2653 - val_accuracy: 0.9682 - val_precision: 0.9686 - val_recall: 0.9686 - val_fmeasure: 0.9686\n",
      "Epoch 64/70\n",
      "139/139 [==============================] - 11s 80ms/step - loss: 0.3709 - accuracy: 0.9697 - precision: 0.9711 - recall: 0.9687 - fmeasure: 0.9699 - val_loss: 0.3326 - val_accuracy: 0.9566 - val_precision: 0.9597 - val_recall: 0.9557 - val_fmeasure: 0.9577\n",
      "Epoch 65/70\n",
      "139/139 [==============================] - 11s 80ms/step - loss: 0.1257 - accuracy: 0.9780 - precision: 0.9798 - recall: 0.9770 - fmeasure: 0.9784 - val_loss: 0.6423 - val_accuracy: 0.9624 - val_precision: 0.9654 - val_recall: 0.9629 - val_fmeasure: 0.9641\n",
      "Epoch 66/70\n",
      "139/139 [==============================] - 11s 81ms/step - loss: 0.1870 - accuracy: 0.9780 - precision: 0.9795 - recall: 0.9763 - fmeasure: 0.9778 - val_loss: 0.3947 - val_accuracy: 0.9653 - val_precision: 0.9696 - val_recall: 0.9629 - val_fmeasure: 0.9662\n",
      "Epoch 67/70\n",
      "139/139 [==============================] - 11s 79ms/step - loss: 0.1783 - accuracy: 0.9805 - precision: 0.9813 - recall: 0.9777 - fmeasure: 0.9794 - val_loss: 0.7861 - val_accuracy: 0.9682 - val_precision: 0.9722 - val_recall: 0.9643 - val_fmeasure: 0.9681\n",
      "Epoch 68/70\n",
      "139/139 [==============================] - 12s 83ms/step - loss: 0.0512 - accuracy: 0.9881 - precision: 0.9899 - recall: 0.9878 - fmeasure: 0.9888 - val_loss: 0.2646 - val_accuracy: 0.9754 - val_precision: 0.9825 - val_recall: 0.9729 - val_fmeasure: 0.9773\n",
      "Epoch 69/70\n",
      "139/139 [==============================] - 11s 78ms/step - loss: 0.0285 - accuracy: 0.9899 - precision: 0.9932 - recall: 0.9896 - fmeasure: 0.9913 - val_loss: 0.1643 - val_accuracy: 0.9740 - val_precision: 0.9769 - val_recall: 0.9743 - val_fmeasure: 0.9756\n",
      "Epoch 70/70\n",
      "139/139 [==============================] - 11s 79ms/step - loss: 0.1387 - accuracy: 0.9881 - precision: 0.9891 - recall: 0.9871 - fmeasure: 0.9881 - val_loss: 0.2613 - val_accuracy: 0.9711 - val_precision: 0.9781 - val_recall: 0.9714 - val_fmeasure: 0.9746\n",
      "22/22 [==============================] - 1s 27ms/step - loss: 0.2613 - accuracy: 0.9711 - precision: 0.9783 - recall: 0.9716 - fmeasure: 0.9749\n",
      "Test loss: 0.26134589314460754\n",
      "Test accuracy: 0.9710982441902161\n",
      "Test precision: 0.9783205389976501\n",
      "Test recall: 0.9715909361839294\n",
      "Test f1-score: 0.974880576133728\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model.compile(\n",
    "\toptimizer=\"Adam\",\n",
    "\tloss=\"categorical_crossentropy\",\n",
    "\tmetrics=['accuracy', precision, recall,fmeasure])\n",
    "\n",
    "model.fit(\n",
    "\tx=X_train, \n",
    "\ty=y_train,\n",
    "    epochs=70,\n",
    "    batch_size=20,\n",
    "    validation_data= (X_test, y_test))\n",
    "\n",
    "score = model.evaluate(\n",
    "\tx=X_test,\n",
    "\ty=y_test)\n",
    "\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "print('Test precision:', score[2])\n",
    "print('Test recall:', score[3])\n",
    "print('Test f1-score:', score[4])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 1s 26ms/step\n"
     ]
    }
   ],
   "source": [
    "\n",
    "predict_x=model.predict(X_test) \n",
    "predictions=np.argmax(predict_x,axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[55,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 1, 64,  0,  0,  0,  0,  1,  0,  0,  0],\n",
       "       [ 0,  0, 69,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0, 76,  0,  0,  1,  0,  0,  0],\n",
       "       [ 0,  0,  1,  0, 50,  2,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0, 70,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  1,  0,  1, 74,  1,  0,  0],\n",
       "       [ 0,  0,  0,  0,  3,  0,  0, 80,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0, 73,  0],\n",
       "       [ 2,  1,  1,  2,  1,  1,  0,  0,  0, 61]], dtype=int64)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf_mat=confusion_matrix(y_test_values, predictions, labels=range(10))\n",
    "conf_mat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Save model to disk\n",
    "### serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(\"./model/model1.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "### serialize weights to HDF5\n",
    "model.save_weights(\"./model/model1.h5\")\n",
    "print(\"Saved model to disk\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n"
     ]
    }
   ],
   "source": [
    "json_file = open('./model/model1.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"./model/model1.h5\")\n",
    "print(\"Loaded model from disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model.compile(\n",
    "\toptimizer=\"Adam\",\n",
    "\tloss=\"categorical_crossentropy\",\n",
    "\tmetrics=['accuracy', precision, recall,fmeasure])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "2.0\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "[8]\n",
      "{2: 'f'}\n",
      "f\n",
      "2.0\n",
      "4.0\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "[8]\n",
      "{2: 'f', 4: 'f'}\n",
      "f\n",
      "4.0\n",
      "6.0\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "[1]\n",
      "{2: 'f', 4: 'f', 6: 'am'}\n",
      "am\n",
      "6.0\n",
      "8.0\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "[9]\n",
      "{2: 'f', 4: 'f', 6: 'am', 8: 'g'}\n",
      "g\n",
      "8.0\n",
      "10.0\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "[1]\n",
      "{2: 'f', 4: 'f', 6: 'am', 8: 'g', 10: 'am'}\n",
      "am\n",
      "10.0\n",
      "12.0\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "[3]\n",
      "{2: 'f', 4: 'f', 6: 'am', 8: 'g', 10: 'am', 12: 'c'}\n",
      "c\n",
      "12.0\n",
      "14.0\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "[3]\n",
      "{2: 'f', 4: 'f', 6: 'am', 8: 'g', 10: 'am', 12: 'c', 14: 'c'}\n",
      "c\n",
      "14.0\n",
      "16.0\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "[6]\n",
      "{2: 'f', 4: 'f', 6: 'am', 8: 'g', 10: 'am', 12: 'c', 14: 'c', 16: 'e'}\n",
      "e\n",
      "16.0\n",
      "18.0\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "[3]\n",
      "{2: 'f', 4: 'f', 6: 'am', 8: 'g', 10: 'am', 12: 'c', 14: 'c', 16: 'e', 18: 'c'}\n",
      "c\n",
      "18.0\n",
      "20.0\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "[3]\n",
      "{2: 'f', 4: 'f', 6: 'am', 8: 'g', 10: 'am', 12: 'c', 14: 'c', 16: 'e', 18: 'c', 20: 'c'}\n",
      "c\n",
      "20.0\n",
      "22.0\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "[1]\n",
      "{2: 'f', 4: 'f', 6: 'am', 8: 'g', 10: 'am', 12: 'c', 14: 'c', 16: 'e', 18: 'c', 20: 'c', 22: 'am'}\n",
      "am\n",
      "22.0\n",
      "24.0\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "[0]\n",
      "{2: 'f', 4: 'f', 6: 'am', 8: 'g', 10: 'am', 12: 'c', 14: 'c', 16: 'e', 18: 'c', 20: 'c', 22: 'am', 24: 'a'}\n",
      "a\n",
      "24.0\n",
      "26.0\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "[9]\n",
      "{2: 'f', 4: 'f', 6: 'am', 8: 'g', 10: 'am', 12: 'c', 14: 'c', 16: 'e', 18: 'c', 20: 'c', 22: 'am', 24: 'a', 26: 'g'}\n",
      "g\n",
      "26.0\n",
      "28.0\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "[1]\n",
      "{2: 'f', 4: 'f', 6: 'am', 8: 'g', 10: 'am', 12: 'c', 14: 'c', 16: 'e', 18: 'c', 20: 'c', 22: 'am', 24: 'a', 26: 'g', 28: 'am'}\n",
      "am\n",
      "28.0\n",
      "30.0\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "[1]\n",
      "{2: 'f', 4: 'f', 6: 'am', 8: 'g', 10: 'am', 12: 'c', 14: 'c', 16: 'e', 18: 'c', 20: 'c', 22: 'am', 24: 'a', 26: 'g', 28: 'am', 30: 'am'}\n",
      "am\n",
      "30.0\n",
      "32.0\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "[1]\n",
      "{2: 'f', 4: 'f', 6: 'am', 8: 'g', 10: 'am', 12: 'c', 14: 'c', 16: 'e', 18: 'c', 20: 'c', 22: 'am', 24: 'a', 26: 'g', 28: 'am', 30: 'am', 32: 'am'}\n",
      "am\n"
     ]
    }
   ],
   "source": [
    "y, sr = librosa.load('./data/mainPrediction/audiofile.wav')\n",
    "total_duration = librosa.get_duration(y=y, sr=sr)\n",
    "iterate = math.floor(total_duration/2)\n",
    "predVal = {}\n",
    "for i in range(0, iterate):\n",
    "    start_time = i*2\n",
    "    start_index = int(start_time * sr)\n",
    "    end_index = int(start_index + (sr*2))\n",
    "    print(start_index/sr)\n",
    "    print(end_index/sr)\n",
    "    segment = y[start_index:end_index]\n",
    "    ps = librosa.feature.melspectrogram(y=segment, sr=sr)\n",
    "    ps = np.array(ps.reshape(1, 128, 87, 1))\n",
    "    predicted = loaded_model.predict(ps)\n",
    "    # print(predicted)\n",
    "    # predVal.append(round(num, 2) for num in predicted[0])\n",
    "    predicted = np.argmax(predicted, axis=1)\n",
    "    print(predicted)\n",
    "    # predVal.append(np.round(predicted[0]))\n",
    "    predVal[int(end_index/sr)]=CLASSES[predicted[0]]\n",
    "    print(predVal)\n",
    "    print(CLASSES[predicted[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['f' 'f' 'am' 'g' 'am' 'c' 'c' 'e' 'c' 'c' 'am' 'a' 'g' 'am' 'am' 'am']\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 1.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.]])"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data = [[item] for item in predVal]\n",
    "data = np.array(predVal)\n",
    "data = data.reshape(-1, 1)\n",
    "# xax = range(0,np.round(total_duration),2)\n",
    "keys = list(predVal.keys())\n",
    "values = list(predVal.values())\n",
    "values = np.array(values)\n",
    "values1 = []\n",
    "for i in values:\n",
    "    values1.append(CLASSES_MAP[i])\n",
    "values1 = np.array(values1)\n",
    "# print(values1.reshape(1, -1))\n",
    "# data = values.reshape(1, -1)\n",
    "# x_values = np.arange(0, iterate*2, 2)\n",
    "# x_value\n",
    "print(values)\n",
    "heatData = np.zeros((len(CLASSES),len(keys)))\n",
    "print(heatData)\n",
    "k=0\n",
    "for i, j in predVal.items():\n",
    "    if k != len(keys):\n",
    "        heatData[CLASSES.index(j)][k] = 1\n",
    "        k = k+1\n",
    "\n",
    "heatData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(50.722222222222214, 0.5, 'Chords')"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "hm = sns.heatmap(heatData, cmap=\"cividis\", yticklabels=CLASSES, xticklabels= keys, linewidths=0.5, linecolor='white') \n",
    "\n",
    "\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Chords\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "x and y must have same first dimension, but have shapes (1,) and (10,)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[227], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Create a scatter plot\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# plt.scatter(keys, CLASSES, marker='o', color='blue')\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCLASSES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmarker\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43ms\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Add labels and a title\u001b[39;00m\n\u001b[0;32m      6\u001b[0m plt\u001b[38;5;241m.\u001b[39mxlabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mX-axis\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\matplotlib\\pyplot.py:2812\u001b[0m, in \u001b[0;36mplot\u001b[1;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2810\u001b[0m \u001b[38;5;129m@_copy_docstring_and_deprecators\u001b[39m(Axes\u001b[38;5;241m.\u001b[39mplot)\n\u001b[0;32m   2811\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mplot\u001b[39m(\u001b[38;5;241m*\u001b[39margs, scalex\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, scaley\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m-> 2812\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m gca()\u001b[38;5;241m.\u001b[39mplot(\n\u001b[0;32m   2813\u001b[0m         \u001b[38;5;241m*\u001b[39margs, scalex\u001b[38;5;241m=\u001b[39mscalex, scaley\u001b[38;5;241m=\u001b[39mscaley,\n\u001b[0;32m   2814\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m: data} \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m {}), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\matplotlib\\axes\\_axes.py:1688\u001b[0m, in \u001b[0;36mAxes.plot\u001b[1;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1445\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1446\u001b[0m \u001b[38;5;124;03mPlot y versus x as lines and/or markers.\u001b[39;00m\n\u001b[0;32m   1447\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1685\u001b[0m \u001b[38;5;124;03m(``'green'``) or hex strings (``'#008000'``).\u001b[39;00m\n\u001b[0;32m   1686\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1687\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m cbook\u001b[38;5;241m.\u001b[39mnormalize_kwargs(kwargs, mlines\u001b[38;5;241m.\u001b[39mLine2D)\n\u001b[1;32m-> 1688\u001b[0m lines \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_lines(\u001b[38;5;241m*\u001b[39margs, data\u001b[38;5;241m=\u001b[39mdata, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)]\n\u001b[0;32m   1689\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m lines:\n\u001b[0;32m   1690\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_line(line)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\matplotlib\\axes\\_base.py:311\u001b[0m, in \u001b[0;36m_process_plot_var_args.__call__\u001b[1;34m(self, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m     this \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m    310\u001b[0m     args \u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m1\u001b[39m:]\n\u001b[1;32m--> 311\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_plot_args\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    312\u001b[0m \u001b[43m    \u001b[49m\u001b[43mthis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mambiguous_fmt_datakey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mambiguous_fmt_datakey\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\matplotlib\\axes\\_base.py:504\u001b[0m, in \u001b[0;36m_process_plot_var_args._plot_args\u001b[1;34m(self, tup, kwargs, return_kwargs, ambiguous_fmt_datakey)\u001b[0m\n\u001b[0;32m    501\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes\u001b[38;5;241m.\u001b[39myaxis\u001b[38;5;241m.\u001b[39mupdate_units(y)\n\u001b[0;32m    503\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m!=\u001b[39m y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]:\n\u001b[1;32m--> 504\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx and y must have same first dimension, but \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    505\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhave shapes \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    506\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m y\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m    507\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx and y can be no greater than 2D, but have \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    508\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshapes \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (1,) and (10,)"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a scatter plot\n",
    "# plt.scatter(keys, CLASSES, marker='o', color='blue')\n",
    "plt.plot(keys, CLASSES, marker=\"s\", color='b')\n",
    "\n",
    "# Add labels and a title\n",
    "plt.xlabel('X-axis')\n",
    "plt.ylabel('Y-axis')\n",
    "plt.title('Scatter Plot')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "0.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
